#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ììœ¨ì£¼í–‰ ë¶„ì„ ë„êµ¬

/captureë¥¼ ì‚¬ìš©í•˜ì—¬ 1ì´ˆë‹¹ 3 í”„ë ˆì„ì„ ë¶„ì„í•˜ê³ 
ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë™ì‹œì— í‘œì‹œí•©ë‹ˆë‹¤.
"""

import cv2
import time
import requests
import numpy as np
from typing import Dict, Any, Tuple

# ESP32-CAM ì„¤ì •
ESP32_IP = "192.168.0.65"
CAPTURE_URL = f"http://{ESP32_IP}/capture"
TARGET_FPS = 3  # 1ì´ˆë‹¹ 3 í”„ë ˆì„

# ìœˆë„ìš° ì´ë¦„
WINDOW_NAME = "ììœ¨ì£¼í–‰ ë¶„ì„ | ì™¼ìª½: ì›ë³¸  ì˜¤ë¥¸ìª½: ë¶„ì„ ê²°ê³¼"


class RealtimeAnalyzer:
    """ì‹¤ì‹œê°„ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        # ì„¸ì…˜ ìƒì„± (ì—°ê²° ì¬ì‚¬ìš©)
        self.session = requests.Session()
        self.session.headers.update(
            {"Connection": "keep-alive", "Keep-Alive": "timeout=5, max=100"}
        )

        # HSV ë²”ìœ„ (íŠ¸ë™ë°”ë¡œ ì¡°ì • ê°€ëŠ¥)
        self.hsv_params = {
            "white_v_min": 200,  # í°ìƒ‰ V ìµœì†Œê°’
            "white_s_max": 30,  # í°ìƒ‰ S ìµœëŒ€ê°’
            "brightness": 80,  # ë°ê¸° ì„ê³„ê°’
            "min_pixels": 200,  # ìµœì†Œ í”½ì…€ ìˆ˜
        }

        # í†µê³„
        self.stats = {
            "frames": 0,
            "errors": 0,
            "start_time": time.time(),
        }

        # CLAHE ì´ˆê¸°í™”
        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

    def create_trackbars(self):
        """íŠ¸ë™ë°” ìƒì„±"""
        cv2.namedWindow(WINDOW_NAME)

        # HSV ë²”ìœ„ ì¡°ì •
        cv2.createTrackbar(
            "White V Min",
            WINDOW_NAME,
            self.hsv_params["white_v_min"],
            255,
            self._on_trackbar,
        )
        cv2.createTrackbar(
            "White S Max",
            WINDOW_NAME,
            self.hsv_params["white_s_max"],
            255,
            self._on_trackbar,
        )
        cv2.createTrackbar(
            "Min Pixels",
            WINDOW_NAME,
            self.hsv_params["min_pixels"],
            1000,
            self._on_trackbar,
        )

    def _on_trackbar(self, value):
        """íŠ¸ë™ë°” ì½œë°± (ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ)"""
        pass

    def get_trackbar_values(self):
        """í˜„ì¬ íŠ¸ë™ë°” ê°’ ê°€ì ¸ì˜¤ê¸°"""
        self.hsv_params["white_v_min"] = cv2.getTrackbarPos("White V Min", WINDOW_NAME)
        self.hsv_params["white_s_max"] = cv2.getTrackbarPos("White S Max", WINDOW_NAME)
        self.hsv_params["min_pixels"] = cv2.getTrackbarPos("Min Pixels", WINDOW_NAME)

    def capture_frame(self) -> Tuple[np.ndarray, float]:
        """
        ë‹¨ì¼ í”„ë ˆì„ ìº¡ì²˜

        Returns:
            (ì´ë¯¸ì§€, ìº¡ì²˜ ì‹œê°„)
        """
        start_time = time.time()

        try:
            response = self.session.get(CAPTURE_URL, timeout=2, stream=True)

            if response.status_code == 200:
                # ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
                content = b""
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        content += chunk

                # ì´ë¯¸ì§€ ë””ì½”ë”©
                nparr = np.frombuffer(content, np.uint8)
                image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                capture_time = (time.time() - start_time) * 1000  # ms
                return image, capture_time

        except Exception as e:
            print(f"âš ï¸ ìº¡ì²˜ ì‹¤íŒ¨: {e}")
            self.stats["errors"] += 1

        return None, 0

    def process_frame(self, image: np.ndarray) -> Dict[str, Any]:
        """
        í”„ë ˆì„ ë¶„ì„

        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        process_start = time.time()

        try:
            # 1. CLAHE ì „ì²˜ë¦¬
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            enhanced = self.clahe.apply(gray)
            enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)

            # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            blurred = cv2.GaussianBlur(enhanced_bgr, (5, 5), 0)

            # 3. ROI ì¶”ì¶œ (í•˜ë‹¨ 25%)
            height, width = blurred.shape[:2]
            roi_y_start = int(height * 0.75)
            roi = blurred[roi_y_start:height, 0:width]

            # 4. HSV ë³€í™˜ ë° ì°¨ì„  ë§ˆìŠ¤í¬ ìƒì„±
            hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

            # íŠ¸ë™ë°” ê°’ìœ¼ë¡œ í°ìƒ‰ ì°¨ì„  ê²€ì¶œ
            white_v_min = self.hsv_params["white_v_min"]
            white_s_max = self.hsv_params["white_s_max"]

            lower_white = np.array([0, 0, white_v_min])
            upper_white = np.array([180, white_s_max, 255])
            mask_white = cv2.inRange(hsv, lower_white, upper_white)

            # ë¹¨ê°„ìƒ‰ ì°¨ì„ 
            lower_red1 = np.array([0, 100, 100])
            upper_red1 = np.array([10, 255, 255])
            mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)

            lower_red2 = np.array([160, 100, 100])
            upper_red2 = np.array([180, 255, 255])
            mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)

            mask_red = cv2.bitwise_or(mask_red1, mask_red2)

            # í†µí•© ë§ˆìŠ¤í¬
            mask = cv2.bitwise_or(mask_white, mask_red)

            # 5. ë…¸ì´ì¦ˆ ì œê±°
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

            # 6. íˆìŠ¤í† ê·¸ë¨ ê³„ì‚° (3ë“±ë¶„)
            third = width // 3
            left_sum = np.sum(mask[:, 0:third] == 255)
            center_sum = np.sum(mask[:, third : third * 2] == 255)
            right_sum = np.sum(mask[:, third * 2 : width] == 255)

            histogram = {
                "left": int(left_sum),
                "center": int(center_sum),
                "right": int(right_sum),
            }

            # 7. ì¡°í–¥ íŒë‹¨
            command, confidence = self._judge_steering(histogram)

            # 8. ë¶„ì„ ì´ë¯¸ì§€ ìƒì„±
            analysis_image = self._draw_analysis(
                image.copy(), mask, roi_y_start, histogram, command, confidence
            )

            process_time = (time.time() - process_start) * 1000  # ms

            return {
                "analysis_image": analysis_image,
                "mask": mask,
                "histogram": histogram,
                "command": command,
                "confidence": confidence,
                "process_time": process_time,
                "roi_y_start": roi_y_start,
            }

        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "analysis_image": image.copy(),
                "mask": None,
                "histogram": {"left": 0, "center": 0, "right": 0},
                "command": "stop",
                "confidence": 0.0,
                "process_time": 0,
                "roi_y_start": 0,
            }

    def _judge_steering(self, histogram: Dict[str, int]) -> Tuple[str, float]:
        """
        ì¡°í–¥ íŒë‹¨

        Args:
            histogram: íˆìŠ¤í† ê·¸ë¨ ë°ì´í„°

        Returns:
            (ëª…ë ¹, ì‹ ë¢°ë„)
        """
        left = histogram["left"]
        center = histogram["center"]
        right = histogram["right"]
        total = left + center + right

        min_pixels = self.hsv_params["min_pixels"]

        # ì°¨ì„ ì´ ê±°ì˜ ì—†ìœ¼ë©´ ì •ì§€
        if total < min_pixels:
            return "stop", 0.0

        # ì •ê·œí™”
        left_ratio = left / total if total > 0 else 0
        center_ratio = center / total if total > 0 else 0
        right_ratio = right / total if total > 0 else 0

        # ë°ë“œì¡´ (ì¢Œìš° ì°¨ì´ê°€ ì ìœ¼ë©´ center)
        deadzone = 0.15
        if abs(left_ratio - right_ratio) < deadzone:
            return "center", center_ratio

        # ì¢Œìš° í¸í–¥ íŒë‹¨
        bias_ratio = 1.3
        if left_ratio > right_ratio * bias_ratio:
            confidence = min(left_ratio / (left_ratio + right_ratio), 1.0)
            return "left", confidence
        elif right_ratio > left_ratio * bias_ratio:
            confidence = min(right_ratio / (left_ratio + right_ratio), 1.0)
            return "right", confidence
        else:
            return "center", center_ratio

    def _draw_analysis(
        self,
        image: np.ndarray,
        mask: np.ndarray,
        roi_y_start: int,
        histogram: Dict[str, int],
        command: str,
        confidence: float,
    ) -> np.ndarray:
        """
        ë¶„ì„ ì´ë¯¸ì§€ ìƒì„±

        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            mask: ì°¨ì„  ë§ˆìŠ¤í¬
            roi_y_start: ROI ì‹œì‘ Y ì¢Œí‘œ
            histogram: íˆìŠ¤í† ê·¸ë¨
            command: ëª…ë ¹
            confidence: ì‹ ë¢°ë„

        Returns:
            ë¶„ì„ ì´ë¯¸ì§€
        """
        height, width = image.shape[:2]

        # ë§ˆìŠ¤í¬ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜
        mask_colored = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)

        # ROI ì˜ì—­ì— ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
        roi_h = height - roi_y_start
        overlay = image.copy()
        overlay[roi_y_start:height, 0:width] = cv2.addWeighted(
            overlay[roi_y_start:height, 0:width], 0.7, mask_colored, 0.3, 0
        )

        # ROI ê²½ê³„ì„ 
        cv2.line(overlay, (0, roi_y_start), (width, roi_y_start), (255, 255, 0), 2)

        # 3ë“±ë¶„ ì„ 
        third = width // 3
        cv2.line(overlay, (third, roi_y_start), (third, height), (100, 100, 100), 1)
        cv2.line(
            overlay, (third * 2, roi_y_start), (third * 2, height), (100, 100, 100), 1
        )

        # ëª…ë ¹ í‘œì‹œ
        command_text = command.upper()
        color = {
            "left": (0, 165, 255),  # ì£¼í™©ìƒ‰
            "right": (255, 0, 255),  # ìí™ìƒ‰
            "center": (0, 255, 0),  # ì´ˆë¡ìƒ‰
            "stop": (0, 0, 255),  # ë¹¨ê°„ìƒ‰
        }.get(command, (255, 255, 255))

        cv2.putText(
            overlay,
            f">>> {command_text} <<<",
            (10, 40),
            cv2.FONT_HERSHEY_DUPLEX,
            1.2,
            color,
            3,
        )

        # íˆìŠ¤í† ê·¸ë¨ í‘œì‹œ
        left = histogram["left"]
        center = histogram["center"]
        right = histogram["right"]

        cv2.putText(
            overlay,
            f"L:{left:4d}  C:{center:4d}  R:{right:4d}",
            (10, height - 60),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),
            2,
        )

        # ì‹ ë¢°ë„ í‘œì‹œ
        cv2.putText(
            overlay,
            f"ì‹ ë¢°ë„: {confidence*100:.1f}%",
            (10, 80),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )

        return overlay

    def run(self):
        """ë©”ì¸ ë£¨í”„ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš— ì‹¤ì‹œê°„ ììœ¨ì£¼í–‰ ë¶„ì„ ë„êµ¬")
        print("=" * 60)
        print(f"ESP32-CAM ì£¼ì†Œ: {ESP32_IP}")
        print(f"íƒ€ê²Ÿ FPS: {TARGET_FPS}")
        print()
        print("ğŸ’¡ ì‚¬ìš©ë²•:")
        print("  - íŠ¸ë™ë°”ë¥¼ ì¡°ì •í•˜ì—¬ íŒŒë¼ë¯¸í„° ë³€ê²½")
        print("  - 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ")
        print("=" * 60)
        print()

        # íŠ¸ë™ë°” ìƒì„±
        self.create_trackbars()

        # FPS ì œì–´
        frame_interval = 1.0 / TARGET_FPS
        last_frame_time = 0

        # FPS ê³„ì‚°
        fps_counter = 0
        fps_start = time.time()
        current_fps = 0

        try:
            while True:
                current_time = time.time()

                # FPS ì œí•œ
                if current_time - last_frame_time < frame_interval:
                    time.sleep(0.01)
                    continue

                last_frame_time = current_time

                # íŠ¸ë™ë°” ê°’ ì—…ë°ì´íŠ¸
                self.get_trackbar_values()

                # í”„ë ˆì„ ìº¡ì²˜
                capture_start = time.time()
                image, capture_time = self.capture_frame()

                if image is None:
                    print("âš ï¸ ìº¡ì²˜ ì‹¤íŒ¨ - ì¬ì‹œë„ ì¤‘...")
                    time.sleep(0.1)
                    continue

                self.stats["frames"] += 1
                fps_counter += 1

                # FPS ê³„ì‚° (1ì´ˆë§ˆë‹¤)
                if current_time - fps_start >= 1.0:
                    current_fps = fps_counter
                    fps_counter = 0
                    fps_start = current_time

                # í”„ë ˆì„ ë¶„ì„
                result = self.process_frame(image)

                total_time = (time.time() - capture_start) * 1000

                # ì›ë³¸ ì´ë¯¸ì§€ì— ì •ë³´ ì¶”ê°€
                original = image.copy()
                cv2.putText(
                    original,
                    "ì›ë³¸ ì´ë¯¸ì§€",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 255, 255),
                    2,
                )

                # ë¶„ì„ ì´ë¯¸ì§€
                analysis = result["analysis_image"]

                # ì‹œê°„ ì •ë³´ í‘œì‹œ
                cv2.putText(
                    analysis,
                    f"ìº¡ì²˜: {capture_time:.1f}ms",
                    (10, height - 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (200, 200, 200),
                    1,
                )

                cv2.putText(
                    analysis,
                    f"ë¶„ì„: {result['process_time']:.1f}ms",
                    (10, height - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (200, 200, 200),
                    1,
                )

                cv2.putText(
                    analysis,
                    f"ì „ì²´: {total_time:.1f}ms",
                    (150, height - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (200, 200, 200),
                    1,
                )

                # FPS í‘œì‹œ
                cv2.putText(
                    analysis,
                    f"FPS: {current_fps}",
                    (width - 120, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0, 255, 0),
                    2,
                )

                # ì¢Œìš° ê²°í•©
                height, width = original.shape[:2]
                combined = cv2.hconcat([original, analysis])

                # í™”ë©´ í‘œì‹œ
                cv2.imshow(WINDOW_NAME, combined)

                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord("q"):
                    print("\nì‚¬ìš©ìê°€ ì¢…ë£Œ ìš”ì²­")
                    break

        except KeyboardInterrupt:
            print("\n\nì‚¬ìš©ìê°€ ì¤‘ë‹¨ (Ctrl+C)")
        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback

            traceback.print_exc()
        finally:
            # í†µê³„ ì¶œë ¥
            elapsed = time.time() - self.stats["start_time"]
            avg_fps = self.stats["frames"] / elapsed if elapsed > 0 else 0

            print("\n" + "=" * 60)
            print("ğŸ“Š ì‹¤í–‰ í†µê³„")
            print("=" * 60)
            print(f"ì²˜ë¦¬ëœ í”„ë ˆì„: {self.stats['frames']}")
            print(f"ì˜¤ë¥˜ ë°œìƒ: {self.stats['errors']}")
            print(f"ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ì´ˆ")
            print(f"í‰ê·  FPS: {avg_fps:.1f}")
            print("=" * 60)

            cv2.destroyAllWindows()
            print("\nì¢…ë£Œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = RealtimeAnalyzer()
    analyzer.run()


if __name__ == "__main__":
    main()
